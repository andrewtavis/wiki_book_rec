{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "authentic-python",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Download-and-Clean-Data\" data-toc-modified-id=\"Download-and-Clean-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Download and Clean Data</a></span></li><li><span><a href=\"#Making-Recommendations\" data-toc-modified-id=\"Making-Recommendations-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Making Recommendations</a></span><ul class=\"toc-item\"><li><span><a href=\"#BERT\" data-toc-modified-id=\"BERT-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>BERT</a></span></li><li><span><a href=\"#Doc2vec\" data-toc-modified-id=\"Doc2vec-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Doc2vec</a></span></li><li><span><a href=\"#LDA\" data-toc-modified-id=\"LDA-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>LDA</a></span></li><li><span><a href=\"#TFIDF\" data-toc-modified-id=\"TFIDF-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>TFIDF</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-anthropology",
   "metadata": {},
   "source": [
    "**rec_movies**:\n",
    "\n",
    "Downloads an English Wikipedia dump and parses it for all available movies. All available models are then ran to compare recommendation efficacy.\n",
    "\n",
    "If using this notebook in [Google Colab](https://colab.research.google.com/github/andrewtavis/wikirec/blob/main/examples/rec_movies.ipynb), you can activate GPUs by following `Edit > Notebook settings > Hardware accelerator` and selecting `GPU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wicked-agreement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:16:50.034150Z",
     "start_time": "2021-03-18T11:16:50.031681Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install wikirec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-place",
   "metadata": {},
   "source": [
    "The following gensim update might be necessary in Google Colab as the default version is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "meaning-tournament",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:16:50.913982Z",
     "start_time": "2021-03-18T11:16:50.911688Z"
    }
   },
   "outputs": [],
   "source": [
    "# pip install gensim -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-disclaimer",
   "metadata": {},
   "source": [
    "In Colab you'll also need to download nltk's names data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "floating-fetish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:17:28.987400Z",
     "start_time": "2021-03-18T11:17:28.985238Z"
    }
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download(\"names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continuing-lebanon",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:18:20.782089Z",
     "start_time": "2021-03-18T11:18:16.575259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:99% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(rc={\"figure.figsize\": (15, 5)})\n",
    "\n",
    "from wikirec import data_utils, model, utils\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:99% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-merit",
   "metadata": {},
   "source": [
    "# Download and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "lucky-niagara",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:18:23.063058Z",
     "start_time": "2021-03-18T11:18:22.253231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already available in the ./enwiki_dump directory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = data_utils.download_wiki(\n",
    "    language=\"en\", target_dir=\"./enwiki_dump\", file_limit=-1, dump_id=False\n",
    ")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "damaged-lawyer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:18:24.649235Z",
     "start_time": "2021-03-18T11:18:24.646935Z"
    }
   },
   "outputs": [],
   "source": [
    "topic = \"movies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vertical-swiss",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:18:24.860592Z",
     "start_time": "2021-03-18T11:18:24.856990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./enwiki_movies.ndjson with articles for the given topics already exists\n"
     ]
    }
   ],
   "source": [
    "data_utils.parse_to_ndjson(\n",
    "    topics=topic,\n",
    "    output_path=\"./enwiki_movies.ndjson\",\n",
    "    input_dir=\"./enwiki_dump\",\n",
    "    partitions_dir=\"./enwiki_movie_partitions\",\n",
    "    limit=None,\n",
    "    delete_parsed_files=True,\n",
    "    multicore=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "handed-farmer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:18:32.274175Z",
     "start_time": "2021-03-18T11:18:29.142617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a total of 141371 movies.\n"
     ]
    }
   ],
   "source": [
    "with open(\"./enwiki_movies.ndjson\", \"r\") as fin:\n",
    "    movies = [json.loads(l) for l in fin]\n",
    "\n",
    "print(f\"Found a total of {len(movies)} movies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "traditional-jefferson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:18:34.295991Z",
     "start_time": "2021-03-18T11:18:34.267707Z"
    }
   },
   "outputs": [],
   "source": [
    "titles = [m[0] for m in movies]\n",
    "texts = [m[1] for m in movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sufficient-cattle",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T11:35:57.216494Z",
     "start_time": "2021-03-18T11:18:49.253028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating movie corpus and selected indexes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3fca93441f47c1bd8ee278ca17a3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning steps complete:   0%|          | 0/7 [00:00<?, ?step/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385646c4c03645eba69db7fe4980d62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "n-grams generated:   0%|          | 0/141371 [00:00<?, ?texts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c6e9ec2fe244b4b7633a9fe8ef8ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stopwords removed:   0%|          | 0/141371 [00:00<?, ?texts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d614f067dc44e6881947ec973158f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Texts lemmatized:   0%|          | 0/141371 [00:00<?, ?texts/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-0910db54063f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mremove_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/wikirec-dev/lib/python3.7/site-packages/wikirec/data_utils.py\u001b[0m in \u001b[0;36mclean\u001b[0;34m(texts, language, min_token_freq, min_token_len, min_tokens, max_token_index, min_ngram_count, remove_stopwords, ignore_words, remove_names, sample_size, verbose)\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mbase_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/wikirec-dev/lib/python3.7/site-packages/wikirec/data_utils.py\u001b[0m in \u001b[0;36m_lemmatize\u001b[0;34m(tokens, nlp, verbose)\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     ):\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mcombined_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_combine_tokens_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mlem_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/wikirec-dev/lib/python3.7/site-packages/wikirec/data_utils.py\u001b[0m in \u001b[0;36m_combine_tokens_to_str\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0munwanted\u001b[0m \u001b[0mwords\u001b[0m \u001b[0mremoved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0mflat_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"./movie_corpus_idxs.pkl\"):\n",
    "    print(f\"Loading movie corpus and selected indexes\")\n",
    "    with open(f\"./movie_corpus_idxs.pkl\", \"rb\") as f:\n",
    "        text_corpus, selected_idxs = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    print(f\"Creating movie corpus and selected indexes\")\n",
    "    text_corpus, selected_idxs = data_utils.clean(\n",
    "        texts=texts,\n",
    "        language=\"en\",\n",
    "        min_token_freq=5,  # 0 for Bert\n",
    "        min_token_len=3,  # 0 for Bert\n",
    "        min_tokens=50,\n",
    "        max_token_index=-1,\n",
    "        min_ngram_count=3,\n",
    "        remove_stopwords=True,  # False for Bert\n",
    "        ignore_words=None,\n",
    "        remove_names=True,\n",
    "        sample_size=1,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    selected_titles = [titles[i] for i in selected_idxs]\n",
    "\n",
    "    with open(\"./movie_corpus_idxs.pkl\", \"wb\") as f:\n",
    "        print(\"Pickling movie corpus and selected indexes\")\n",
    "        pickle.dump([text_corpus, selected_idxs], f, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-transsexual",
   "metadata": {},
   "source": [
    "# Making Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-census",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T19:51:37.298726Z",
     "start_time": "2021-03-07T19:51:37.296372Z"
    }
   },
   "outputs": [],
   "source": [
    "single_input_0 = \"The Godfather\"\n",
    "single_input_1 = \"The Dark Knight\"\n",
    "mutliple_inputs = [\"The Godfather\", \"The Dark Knight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_create_sim_matrix(\n",
    "    method,\n",
    "    corpus,\n",
    "    metric,\n",
    "    topic,\n",
    "    path=\"./\",\n",
    "    bert_st_model=\"xlm-r-bert-base-nli-stsb-mean-tokens\",\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads or creats a similarity matrix to deliver recommendations\n",
    "    \n",
    "    NOTE: the .pkl files made are 10-20GB or more in size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(f\"{path}{topic}_{metric}_{method}_sim_matrix.pkl\"):\n",
    "        print(f\"Loading {method} {topic} {metric} similarity matrix\")\n",
    "        with open(f\"{path}{topic}_{metric}_{method}_sim_matrix.pkl\", \"rb\") as f:\n",
    "            sim_matrix = pickle.load(f)\n",
    "\n",
    "    else:\n",
    "        print(f\"Creating {method} {topic} {metric} similarity matrix\")\n",
    "        embeddings = model.gen_embeddings(\n",
    "            method=method, corpus=corpus, bert_st_model=bert_st_model, **kwargs,\n",
    "        )\n",
    "        sim_matrix = model.gen_sim_matrix(\n",
    "            method=method, metric=metric, embeddings=embeddings,\n",
    "        )\n",
    "\n",
    "        with open(f\"{path}{topic}_{metric}_{method}_sim_matrix.pkl\", \"wb\") as f:\n",
    "            print(f\"Pickling {method} {topic} {metric} similarity matrix\")\n",
    "            pickle.dump(sim_matrix, f, protocol=4)\n",
    "\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-session",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove n-grams for BERT training\n",
    "corpus_no_ngrams = [\n",
    "    \" \".join([t for t in text.split(\" \") if \"_\" not in t]) for text in text_corpus\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can pass kwargs for sentence_transformers.SentenceTransformer.encode\n",
    "bert_sim_matrix = load_or_create_sim_matrix(\n",
    "    method=\"bert\",\n",
    "    corpus=corpus_no_ngrams,\n",
    "    metric=\"cosine\",  # euclidean\n",
    "    topic=topic,\n",
    "    path=\"./\",\n",
    "    bert_st_model=\"xlm-r-bert-base-nli-stsb-mean-tokens\",\n",
    "    show_progress_bar=True,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recommend(\n",
    "    inputs=single_input_0,\n",
    "    titles=selected_titles,\n",
    "    sim_matrix=bert_sim_matrix,\n",
    "    n=10,\n",
    "    metric=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recommend(\n",
    "    inputs=single_input_1,\n",
    "    titles=selected_titles,\n",
    "    sim_matrix=bert_sim_matrix,\n",
    "    n=10,\n",
    "    metric=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-emission",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T04:12:53.366133Z",
     "start_time": "2021-03-08T04:00:34.053166Z"
    }
   },
   "outputs": [],
   "source": [
    "model.recommend(\n",
    "    inputs=multiple_inputs,\n",
    "    titles=selected_titles,\n",
    "    sim_matrix=bert_sim_matrix,\n",
    "    n=10,\n",
    "    metric=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-pound",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-underwear",
   "metadata": {},
   "source": [
    "Note: Doc2vec wasn't ran because of runtime considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can pass kwargs for gensim.models.doc2vec.Doc2Vec\n",
    "doc2vec_sim_matrix = load_or_create_sim_matrix(\n",
    "    method=\"doc2vec\",\n",
    "    corpus=text_corpus,\n",
    "    metric=\"cosine\",  # euclidean\n",
    "    topic=topic,\n",
    "    path=\"./\",\n",
    "    vector_size=100,\n",
    "    epochs=10,\n",
    "    alpha=0.025,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recommend(\n",
    "    inputs=single_input_0,\n",
    "    titles=selected_titles,\n",
    "    sim_matrix=doc2vec_sim_matrix,\n",
    "    n=10,\n",
    "    metric=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-undergraduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recommend(\n",
    "    inputs=single_input_1,\n",
    "    titles=selected_titles,\n",
    "    sim_matrix=doc2vec_sim_matrix,\n",
    "    n=10,\n",
    "    metric=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-program",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-07T20:09:31.182Z"
    }
   },
   "outputs": [],
   "source": [
    "model.recommend(\n",
    "    inputs=multiple_inputs,\n",
    "    titles=selected_titles,\n",
    "    sim_matrix=doc2vec_sim_matrix,\n",
    "    n=10,\n",
    "    metric=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-steps",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-school",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-07T20:09:33.322Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_nums_to_compare = [1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "# We can pass kwargs for gensim.models.ldamulticore.LdaMulticore\n",
    "utils.graph_lda_topic_evals(\n",
    "    corpus=text_corpus,\n",
    "    num_topic_words=10,\n",
    "    topic_nums_to_compare=topic_nums_to_compare,\n",
    "    metrics=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-isolation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T11:18:14.370829Z",
     "start_time": "2021-03-06T11:18:13.700035Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can pass kwargs for gensim.models.ldamulticore.LdaMulticore\n",
    "lda_sim_matrix = load_or_create_sim_matrix(\n",
    "    method=\"lda\",\n",
    "    corpus=text_corpus,\n",
    "    metric=\"cosine\",  # euclidean not an option at this time\n",
    "    topic=topic,\n",
    "    path=\"./\",\n",
    "    num_topics=90,\n",
    "    passes=10,\n",
    "    decay=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recommend(\n",
    "    inputs=single_input_0,\n",
    "    titles=selected_titles,\n",
    "    sim_matrix=lda_sim_matrix,\n",
    "    n=10,\n",
    "    metric=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recommend(\n",
    "    inputs=single_input_1,\n",
    "    titles=selected_titles,\n",
    "    sim_matrix=lda_sim_matrix,\n",
    "    n=10,\n",
    "    metric=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-intelligence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T11:18:15.671225Z",
     "start_time": "2021-03-06T11:18:15.664946Z"
    }
   },
   "outputs": [],
   "source": [
    "model.recommend(\n",
    "    inputs=multiple_inputs,\n",
    "    titles=selected_titles,\n",
    "    sim_matrix=lda_sim_matrix,\n",
    "    n=10,\n",
    "    metric=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-brook",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-trader",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T11:20:32.957646Z",
     "start_time": "2021-03-06T11:20:32.910427Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can pass kwargs for sklearn.feature_extraction.text.TfidfVectorizer\n",
    "tfidf_sim_matrix = load_or_create_sim_matrix(\n",
    "    method=\"tfidf\",\n",
    "    corpus=text_corpus,\n",
    "    metric=\"cosine\",  # euclidean\n",
    "    topic=topic,\n",
    "    path=\"./\",\n",
    "    max_features=None,\n",
    "    norm='l2',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recommend(\n",
    "    inputs=single_input_0,\n",
    "    titles=selected_titles,\n",
    "    sim_matrix=tfidf_sim_matrix,\n",
    "    n=10,\n",
    "    metric=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recommend(\n",
    "    inputs=single_input_0,\n",
    "    titles=selected_titles,\n",
    "    sim_matrix=tfidf_sim_matrix,\n",
    "    n=10,\n",
    "    metric=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-scratch",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T11:20:33.836968Z",
     "start_time": "2021-03-06T11:20:33.831822Z"
    }
   },
   "outputs": [],
   "source": [
    "model.recommend(\n",
    "    inputs=multiple_inputs,\n",
    "    titles=selected_titles,\n",
    "    sim_matrix=tfidf_sim_matrix,\n",
    "    n=10,\n",
    "    metric=\"cosine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-cleveland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wikirec-dev] *",
   "language": "python",
   "name": "conda-env-wikirec-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
